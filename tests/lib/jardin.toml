version = 1

# Config, or flag, or ENV var
[pipeline]
force = false # force even if pre-check fails
fresh_install = true # drop data and statefull secrets and reinstall everything
dry-run = false # only check things without applying them

[cluster]
name = "cluster"
dns_zone = "nofreedisk.space"
# set from git slug
version = ""

[accounts]
[accounts.users]


[applications]
[applications.jellyfin]
visibility = "public" # private, etc.., restricted ??
public_dns_alias = "media" # media.nofreedisk.space

[applications.jellyfin.couplings]
# OR ? [applications.jellyfin.dependencies]
# Needed to start
# disnix intra = mariadb -> hot storage
[applications.jellyfin.couplings.hard.mariadb]
[applications.jellyfin.couplings.hard.xxxx]
local = true

# Needed to be available
soft = []
# Needed to be healthy 
weak = ["nextcloud"] # not really

[applications.jellyfin.workload]
cpu_limit = "2"
memory_limit = "2G"
runtime = "container" # systemd(container), vm, kubernetes, nomad(systemd, container, ..)
# This workload position is checked in regards of the couplings
try_nodes = [
  "node1"
  "node2"
  "node3"
]
replicas = 1

# each application expect named cold and hot storage
[applications.jellyfin.storage.cold.media] 
size = "2T"
[applications.jellyfin.storage.hot.configs]
size = "2G"

# jardin peut calculer que la taille totale du pool n'est pas < à la some des claims par machines ou par applications
[cluster.storage.hot]
size = 12G
replicas = 1
sharable = false # Peut pas etre claim pas plus de 1 noeud

[cluster.storage.cold.movies]
size = 132G # = 12 + 110
# Je suis pas sure que c'est utile, mais a voir
sharable = true # Peut pas etre claim par plusieurs noeuds
replicas = 3 # Peut pas marcher y'a que 2 noeuds, peut pas marcher avec sharable = false

# [cluster.secrets] # Ici pour pourrait gérer les secrets
# seed = DZJIECZZECdze12 # Seed pour générer les secrets. 

[cluster.nodes]

[cluster.nodes.node1]

[cluster.nodes.node1.network.wan]
ip = "1.29.123.12.1" # IP publique
region = "eu/paris-1"

[cluster.nodes.node1.network.lan.scaleway1]
ip = 192.168.1.2 # ip privée virtuelle ou physique

# Le stockage doit il etre déclaré ou découvert: combien de disque et quelle taille
[cluster.nodes.node1.storage.system]
size = 12G

[cluster.nodes.node1.storage.hot.database]
size = 12G

[cluster.nodes.node1.storage.cold.movies] # Ici on claim le cluster storage movies
size = 110G
# Tout ca c'est du garage ou iscsi, ou longhorn ou autre.
replicas = 3
# e.g:
strategy = "local" # or resiliant.
# local:
#  self > same lan > wan
# resiliant:
#  self > wan > lan

[cluster.nodes.node2]
[cluster.nodes.node2.network.wan]
public_ip = 1.29.123.12.1
region = eu/paris-2

[cluster.nodes.node2.network.lan.ovh1]
ip = 192.165.1.2

[cluster.nodes.node2.storage.cold.movies]
size = 12G
